{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anova Insurance – Health Classification Model\n",
    "**Objective:** Predict whether an individual is *Healthy (0)* or *Unhealthy (1)* to assist in premium pricing decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 1. IMPORTS ──────────────────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, ConfusionMatrixDisplay, accuracy_score\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Optional – XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "\n",
    "SEED = 42\n",
    "sns.set_theme(style='whitegrid', palette='muted')\n",
    "print('Libraries loaded successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load & Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mDugQt7wQOKNNIAFjVku_Healthcare_Data_Preprocessed_FIXED.csv')\n",
    "print(f'Shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values per column:')\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "target_counts = df['Target'].value_counts()\n",
    "ax.bar(['Healthy (0)', 'Unhealthy (1)'], target_counts.values, color=['steelblue', 'tomato'])\n",
    "ax.set_title('Target Class Distribution')\n",
    "ax.set_ylabel('Count')\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    ax.text(i, v + 30, str(v), ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(target_counts / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical feature distributions\n",
    "num_cols = ['Age', 'BMI', 'Blood_Pressure', 'Cholesterol', 'Glucose_Level',\n",
    "            'Heart_Rate', 'Sleep_Hours', 'Exercise_Hours', 'Water_Intake', 'Stress_Level']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(num_cols):\n",
    "    axes[i].hist(df[col].dropna(), bins=30, color='steelblue', edgecolor='white')\n",
    "    axes[i].set_title(col)\n",
    "plt.suptitle('Numerical Feature Distributions', fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots by Target\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(num_cols):\n",
    "    df.boxplot(column=col, by='Target', ax=axes[i])\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Target')\n",
    "plt.suptitle('Numerical Features by Target Class', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical feature counts\n",
    "cat_cols = ['Smoking', 'Alcohol', 'Diet', 'MentalHealth', 'PhysicalActivity']\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, col in enumerate(cat_cols):\n",
    "    df.groupby([col, 'Target']).size().unstack().plot(kind='bar', ax=axes[i],\n",
    "                                                      color=['steelblue', 'tomato'])\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].tick_params(axis='x', rotation=0)\n",
    "plt.suptitle('Categorical Features vs Target', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "bool_cols = ['Diet_Type_Vegan', 'Diet_Type_Vegetarian',\n",
    "             'Blood_Group_AB', 'Blood_Group_B', 'Blood_Group_O']\n",
    "corr_df = df.copy()\n",
    "for c in bool_cols:\n",
    "    corr_df[c] = corr_df[c].astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "corr_matrix = corr_df.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            linewidths=0.5, ax=ax)\n",
    "ax.set_title('Correlation Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 4.1 Fix negative ages (data entry errors) ──\n",
    "print(f'Negative age values: {(df[\"Age\"] < 0).sum()}')\n",
    "df['Age'] = df['Age'].abs()\n",
    "\n",
    "# ── 4.2 Convert bool columns to int ──\n",
    "for c in bool_cols:\n",
    "    df[c] = df[c].astype(int)\n",
    "\n",
    "# ── 4.3 Feature / target split ──\n",
    "X = df.drop(columns=['Target'])\n",
    "y = df['Target']\n",
    "print(f'Features: {X.shape[1]}, Samples: {X.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 4.4 Train / Test split (80/20, stratified) ──\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=SEED, stratify=y\n",
    ")\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 4.5 Preprocessing pipeline: impute → scale ──\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler  = StandardScaler()\n",
    "\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_test_imp  = imputer.transform(X_test)\n",
    "\n",
    "X_train_sc = scaler.fit_transform(X_train_imp)\n",
    "X_test_sc  = scaler.transform(X_test_imp)\n",
    "\n",
    "print('Preprocessing complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    'Decision Tree':       DecisionTreeClassifier(random_state=SEED),\n",
    "    'Random Forest':       RandomForestClassifier(n_estimators=200, random_state=SEED),\n",
    "    'Gradient Boosting':   GradientBoostingClassifier(n_estimators=200, random_state=SEED),\n",
    "    'KNN':                 KNeighborsClassifier(n_neighbors=7),\n",
    "    'SVM':                 SVC(probability=True, random_state=SEED),\n",
    "}\n",
    "if HAS_XGB:\n",
    "    models['XGBoost'] = XGBClassifier(n_estimators=200, random_state=SEED,\n",
    "                                       use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train_sc, y_train, cv=cv, scoring='roc_auc')\n",
    "    model.fit(X_train_sc, y_train)\n",
    "    y_pred = model.predict(X_test_sc)\n",
    "    y_prob = model.predict_proba(X_test_sc)[:, 1]\n",
    "    results[name] = {\n",
    "        'CV AUC (mean)': cv_scores.mean(),\n",
    "        'CV AUC (std)':  cv_scores.std(),\n",
    "        'Test Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Test AUC':      roc_auc_score(y_test, y_prob),\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "    }\n",
    "    print(f'{name:<25} CV AUC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f} | '\n",
    "          f'Test Acc: {accuracy_score(y_test, y_pred):.4f} | '\n",
    "          f'Test AUC: {roc_auc_score(y_test, y_prob):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary DataFrame\n",
    "results_df = pd.DataFrame([\n",
    "    {'Model': k, 'CV AUC (mean)': v['CV AUC (mean)'], 'CV AUC (std)': v['CV AUC (std)'],\n",
    "     'Test Accuracy': v['Test Accuracy'], 'Test AUC': v['Test AUC']}\n",
    "    for k, v in results.items()\n",
    "]).sort_values('Test AUC', ascending=False).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "results_df.plot(x='Model', y='Test Accuracy', kind='bar', ax=axes[0],\n",
    "                color='steelblue', legend=False)\n",
    "axes[0].set_title('Test Accuracy by Model')\n",
    "axes[0].set_ylim(0.5, 1)\n",
    "axes[0].tick_params(axis='x', rotation=30)\n",
    "\n",
    "results_df.plot(x='Model', y='Test AUC', kind='bar', ax=axes[1],\n",
    "                color='tomato', legend=False)\n",
    "axes[1].set_title('Test ROC-AUC by Model')\n",
    "axes[1].set_ylim(0.5, 1)\n",
    "axes[1].tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Model – Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = results_df.iloc[0]['Model']\n",
    "best      = results[best_name]\n",
    "print(f'Best model: {best_name}')\n",
    "\n",
    "# Classification Report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, best['y_pred'],\n",
    "                             target_names=['Healthy', 'Unhealthy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, best['y_pred'],\n",
    "    display_labels=['Healthy', 'Unhealthy'],\n",
    "    cmap='Blues', ax=ax\n",
    ")\n",
    "ax.set_title(f'Confusion Matrix – {best_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves for all models\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for name, res in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, res['y_prob'])\n",
    "    ax.plot(fpr, tpr, label=f\"{name} (AUC={res['Test AUC']:.3f})\")\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves – All Models')\n",
    "ax.legend(loc='lower right', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X.columns)\n",
    "\n",
    "# Try tree-based importances first, fall back to logistic regression coefficients\n",
    "model_obj = best['model']\n",
    "\n",
    "if hasattr(model_obj, 'feature_importances_'):\n",
    "    importances = model_obj.feature_importances_\n",
    "    imp_type = 'Feature Importance'\n",
    "elif hasattr(model_obj, 'coef_'):\n",
    "    importances = np.abs(model_obj.coef_[0])\n",
    "    imp_type = '|Coefficient|'\n",
    "else:\n",
    "    # Use Random Forest as fallback\n",
    "    rf_fallback = RandomForestClassifier(n_estimators=100, random_state=SEED)\n",
    "    rf_fallback.fit(X_train_sc, y_train)\n",
    "    importances = rf_fallback.feature_importances_\n",
    "    imp_type = 'RF Feature Importance (fallback)'\n",
    "\n",
    "imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "imp_df = imp_df.sort_values('Importance', ascending=True).tail(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.barh(imp_df['Feature'], imp_df['Importance'], color='steelblue')\n",
    "ax.set_xlabel(imp_type)\n",
    "ax.set_title(f'{imp_type} – {best_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_health_status(input_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Predict healthy/unhealthy for a new individual.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dict : dict with feature values (matching column names)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict with prediction label and probability\n",
    "    \"\"\"\n",
    "    sample = pd.DataFrame([input_dict], columns=feature_names)\n",
    "    sample_imp = imputer.transform(sample)\n",
    "    sample_sc  = scaler.transform(sample_imp)\n",
    "    pred  = model_obj.predict(sample_sc)[0]\n",
    "    prob  = model_obj.predict_proba(sample_sc)[0][1]\n",
    "    label = 'Unhealthy' if pred == 1 else 'Healthy'\n",
    "    return {'prediction': label, 'unhealthy_probability': round(prob, 4)}\n",
    "\n",
    "\n",
    "# Example usage\n",
    "example = {\n",
    "    'Age': 45, 'BMI': 28.5, 'Blood_Pressure': 130, 'Cholesterol': 210,\n",
    "    'Glucose_Level': 105, 'Heart_Rate': 80, 'Sleep_Hours': 6, 'Exercise_Hours': 0.5,\n",
    "    'Water_Intake': 1.5, 'Stress_Level': 7, 'Smoking': 2, 'Alcohol': 1, 'Diet': 0,\n",
    "    'MentalHealth': 1, 'PhysicalActivity': 0, 'MedicalHistory': 1, 'Allergies': 0,\n",
    "    'Diet_Type_Vegan': 0, 'Diet_Type_Vegetarian': 0,\n",
    "    'Blood_Group_AB': 0, 'Blood_Group_B': 1, 'Blood_Group_O': 0\n",
    "}\n",
    "print(predict_health_status(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('MODEL PERFORMANCE SUMMARY')\n",
    "print('=' * 60)\n",
    "print(results_df.to_string(index=False))\n",
    "print()\n",
    "print(f'Best Model  : {best_name}')\n",
    "print(f'Test AUC    : {best[\"Test AUC\"]:.4f}')\n",
    "print(f'Test Accuracy: {best[\"Test Accuracy\"]:.4f}')\n",
    "print('=' * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
