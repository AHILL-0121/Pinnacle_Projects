{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Quality Prediction using Deep Learning Neural Networks\n",
    "### Central Pollution Control Board (CPCB) Dataset\n",
    "\n",
    "This notebook builds Deep Learning Neural Networks (Multi-Layer Perceptrons) to predict:\n",
    "1. **Water Quality Index (WQI)** – Regression task\n",
    "2. **Water Quality Classification** – Multi-class classification task\n",
    "\n",
    "**Dataset:** 19,029 records with 15 water quality indicators measured across India (2019–2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_squared_error, mean_absolute_error,\n",
    "    accuracy_score, f1_score, classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "print('All libraries imported successfully.')\n",
    "print(f'NumPy  : {np.__version__}')\n",
    "print(f'Pandas : {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('water_quality.csv')\n",
    "print('Dataset Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Column Data Types:')\n",
    "print(df.dtypes)\n",
    "print('\\nMissing Values per Column:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Descriptive Statistics:')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Water Quality Classification Distribution:')\n",
    "print(df['Water Quality Classification'].value_counts())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "class_counts = df['Water Quality Classification'].value_counts()\n",
    "axes[0].bar(class_counts.index, class_counts.values,\n",
    "            color=sns.color_palette('viridis', len(class_counts)))\n",
    "axes[0].set_title('Water Quality Classification Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Classification')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=20)\n",
    "\n",
    "axes[1].hist(df['WQI'], bins=60, color='steelblue', edgecolor='white')\n",
    "axes[1].set_title('WQI Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('WQI')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = ['Year', 'pH', 'EC', 'CO3', 'HCO3', 'Cl', 'SO4',\n",
    "                'NO3', 'TH', 'Ca', 'Mg', 'Na', 'K', 'F', 'TDS']\n",
    "\n",
    "TARGET_REGRESSION     = 'WQI'\n",
    "TARGET_CLASSIFICATION = 'Water Quality Classification'\n",
    "\n",
    "required_cols = FEATURE_COLS + [TARGET_REGRESSION, TARGET_CLASSIFICATION]\n",
    "df_clean = df[required_cols].dropna().reset_index(drop=True)\n",
    "\n",
    "print(f'Original rows : {len(df)}')\n",
    "print(f'After cleaning: {len(df_clean)}')\n",
    "print(f'Rows dropped  : {len(df) - len(df_clean)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean[FEATURE_COLS].values\n",
    "y_reg   = df_clean[TARGET_REGRESSION].values\n",
    "y_class = df_clean[TARGET_CLASSIFICATION].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_class_enc = le.fit_transform(y_class)\n",
    "\n",
    "print('Classes       :', le.classes_)\n",
    "print('Encoded labels:', np.unique(y_class_enc))\n",
    "print(f'Features: {X.shape[1]}, Samples: {X.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X, y_class_enc, test_size=0.2, random_state=42, stratify=y_class_enc\n",
    ")\n",
    "\n",
    "print(f'Regression     — Train: {X_train_r.shape}, Test: {X_test_r.shape}')\n",
    "print(f'Classification — Train: {X_train_c.shape}, Test: {X_test_c.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_r = StandardScaler()\n",
    "X_train_r_sc = scaler_r.fit_transform(X_train_r)\n",
    "X_test_r_sc  = scaler_r.transform(X_test_r)\n",
    "\n",
    "scaler_c = StandardScaler()\n",
    "X_train_c_sc = scaler_c.fit_transform(X_train_c)\n",
    "X_test_c_sc  = scaler_c.transform(X_test_c)\n",
    "\n",
    "print('StandardScaler applied. Features have zero mean and unit variance.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "corr_matrix = df_clean[FEATURE_COLS + [TARGET_REGRESSION]].corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, ax=ax, linewidths=0.5, annot_kws={'size': 8})\n",
    "ax.set_title('Feature Correlation Heatmap (with WQI)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wqi_corr = corr_matrix['WQI'].drop('WQI').abs().sort_values(ascending=False)\n",
    "plt.figure(figsize=(9, 5))\n",
    "wqi_corr.plot(kind='bar', color='steelblue', edgecolor='white')\n",
    "plt.title('Feature Correlation with WQI (Absolute)', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Absolute Correlation')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Top 5 correlated features with WQI:')\n",
    "print(wqi_corr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "order = df_clean.groupby('Water Quality Classification')['WQI'].median().sort_values().index\n",
    "sns.boxplot(data=df_clean, x='Water Quality Classification', y='WQI',\n",
    "            order=order, palette='viridis')\n",
    "plt.title('WQI Distribution by Water Quality Class', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 1 — WQI Regression (Deep Neural Network)\n",
    "\n",
    "**Architecture:** `Input(15)` → `Dense(512, ReLU)` → `Dense(256, ReLU)` → `Dense(128, ReLU)` → `Dense(64, ReLU)` → `Output(1, Linear)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(512, 256, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    batch_size=256,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=20,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print('Architecture: 15 -> 512 -> 256 -> 128 -> 64 -> 1')\n",
    "print('Optimizer   : Adam (lr=0.001) | Early Stopping | Batch=256')\n",
    "print('Training...')\n",
    "reg_model.fit(X_train_r_sc, y_train_r)\n",
    "print(f'Done. Iterations: {reg_model.n_iter_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_r = reg_model.predict(X_train_r_sc)\n",
    "y_pred_test_r  = reg_model.predict(X_test_r_sc)\n",
    "\n",
    "r2_train  = r2_score(y_train_r, y_pred_train_r)\n",
    "r2_test   = r2_score(y_test_r,  y_pred_test_r)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_r, y_pred_test_r))\n",
    "mae_test  = mean_absolute_error(y_test_r, y_pred_test_r)\n",
    "\n",
    "print('=' * 50)\n",
    "print('    WQI REGRESSION METRICS')\n",
    "print('=' * 50)\n",
    "print(f'  R² Score (Train) : {r2_train:.4f}')\n",
    "print(f'  R² Score (Test)  : {r2_test:.4f}')\n",
    "print(f'  RMSE     (Test)  : {rmse_test:.4f}')\n",
    "print(f'  MAE      (Test)  : {mae_test:.4f}')\n",
    "print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(reg_model.loss_curve_, color='steelblue', linewidth=2)\n",
    "axes[0].set_title('Regression — Training Loss Curve', fontweight='bold')\n",
    "axes[0].set_xlabel('Iterations')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].scatter(y_test_r, y_pred_test_r, alpha=0.25, s=8, color='steelblue')\n",
    "mn, mx = y_test_r.min(), y_test_r.max()\n",
    "axes[1].plot([mn, mx], [mn, mx], 'r--', lw=2, label='Perfect Fit')\n",
    "axes[1].set_title(f'WQI: Actual vs Predicted  R²={r2_test:.4f}', fontweight='bold')\n",
    "axes[1].set_xlabel('Actual WQI')\n",
    "axes[1].set_ylabel('Predicted WQI')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test_r - y_pred_test_r\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "axes[0].scatter(y_pred_test_r, residuals, alpha=0.25, s=8, color='darkorange')\n",
    "axes[0].axhline(0, color='red', lw=2, linestyle='--')\n",
    "axes[0].set_title('Residuals vs Predicted Values', fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted WQI')\n",
    "axes[0].set_ylabel('Residuals')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(residuals, bins=60, color='darkorange', edgecolor='white')\n",
    "axes[1].set_title('Residuals Distribution', fontweight='bold')\n",
    "axes[1].set_xlabel('Residual')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 2 — Water Quality Classification (Deep Neural Network)\n",
    "\n",
    "**Architecture:** `Input(15)` → `Dense(512, ReLU)` → `Dense(256, ReLU)` → `Dense(128, ReLU)` → `Dense(64, ReLU)` → `Output(5, Softmax)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    batch_size=256,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=20,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print('Architecture: 15 -> 512 -> 256 -> 128 -> 64 -> 5(Softmax)')\n",
    "print('Optimizer   : Adam | Loss: Cross-Entropy | Early Stopping')\n",
    "print('Classes     :', list(le.classes_))\n",
    "print('Training...')\n",
    "clf_model.fit(X_train_c_sc, y_train_c)\n",
    "print(f'Done. Iterations: {clf_model.n_iter_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_c = clf_model.predict(X_train_c_sc)\n",
    "y_pred_test_c  = clf_model.predict(X_test_c_sc)\n",
    "\n",
    "acc_train   = accuracy_score(y_train_c, y_pred_train_c)\n",
    "acc_test    = accuracy_score(y_test_c,  y_pred_test_c)\n",
    "f1_macro    = f1_score(y_test_c, y_pred_test_c, average='macro')\n",
    "f1_weighted = f1_score(y_test_c, y_pred_test_c, average='weighted')\n",
    "\n",
    "print('=' * 58)\n",
    "print('  WATER QUALITY CLASSIFICATION METRICS')\n",
    "print('=' * 58)\n",
    "print(f'  Accuracy       (Train) : {acc_train:.4f}')\n",
    "print(f'  Accuracy       (Test)  : {acc_test:.4f}')\n",
    "print(f'  F1 Score Macro (Test)  : {f1_macro:.4f}')\n",
    "print(f'  F1 Score Wtd   (Test)  : {f1_weighted:.4f}')\n",
    "print('=' * 58)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test_c, y_pred_test_c, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(clf_model.loss_curve_, color='steelblue', linewidth=2, label='Train Loss')\n",
    "if hasattr(clf_model, 'validation_scores_') and clf_model.validation_scores_ is not None:\n",
    "    ax2 = plt.twinx()\n",
    "    ax2.plot(clf_model.validation_scores_, color='darkorange', linewidth=2, alpha=0.8, label='Val Acc')\n",
    "    ax2.set_ylabel('Validation Accuracy', color='darkorange')\n",
    "    ax2.legend(loc='lower right')\n",
    "plt.title('Classification Model — Training Loss Curve', fontweight='bold')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_c, y_pred_test_c)\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=le.classes_, yticklabels=le.classes_, linewidths=0.5)\n",
    "plt.title(f'Confusion Matrix — Classification  Acc={acc_test:.4f}',\n",
    "          fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=25, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = classification_report(y_test_c, y_pred_test_c,\n",
    "                                     target_names=le.classes_, output_dict=True)\n",
    "classes = le.classes_\n",
    "f1_pc   = [report_dict[c]['f1-score']  for c in classes]\n",
    "prec_pc = [report_dict[c]['precision'] for c in classes]\n",
    "rec_pc  = [report_dict[c]['recall']    for c in classes]\n",
    "\n",
    "x = np.arange(len(classes))\n",
    "w = 0.25\n",
    "fig, ax = plt.subplots(figsize=(11, 5))\n",
    "ax.bar(x - w, prec_pc, w, label='Precision', color='steelblue', edgecolor='white')\n",
    "ax.bar(x,     rec_pc,  w, label='Recall',    color='darkorange', edgecolor='white')\n",
    "ax.bar(x + w, f1_pc,   w, label='F1-Score',  color='seagreen',  edgecolor='white')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes, rotation=20, ha='right')\n",
    "ax.set_ylim(0, 1.08)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Per-Class Precision, Recall & F1-Score', fontweight='bold', fontsize=13)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 62)\n",
    "print('        FINAL MODEL PERFORMANCE SUMMARY')\n",
    "print('=' * 62)\n",
    "print('\\n[Model 1]  WQI Regression — Deep Neural Network')\n",
    "print('  Architecture : 15 -> 512 -> 256 -> 128 -> 64 -> 1')\n",
    "print('  Optimizer    : Adam (lr=0.001) | Early Stopping')\n",
    "print(f'  R² Score Train : {r2_train:.4f}')\n",
    "print(f'  R² Score Test  : {r2_test:.4f}')\n",
    "print(f'  RMSE     Test  : {rmse_test:.4f}')\n",
    "print(f'  MAE      Test  : {mae_test:.4f}')\n",
    "print('\\n[Model 2]  Water Quality Classification — Deep Neural Network')\n",
    "print('  Architecture : 15 -> 512 -> 256 -> 128 -> 64 -> 5')\n",
    "print('  Optimizer    : Adam | Loss: Cross-Entropy')\n",
    "print(f'  Accuracy Train : {acc_train:.4f}')\n",
    "print(f'  Accuracy Test  : {acc_test:.4f}')\n",
    "print(f'  F1-Macro Test  : {f1_macro:.4f}')\n",
    "print(f'  F1-Wtd   Test  : {f1_weighted:.4f}')\n",
    "print('\\n' + '=' * 62)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
